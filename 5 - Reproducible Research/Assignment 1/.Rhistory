airquality <- transform(airquality, Month = factor(Month))
# p <- xyplot(Ozone ~ Wind | Month, data = airquality, layout = c(5, 1))
p <- xyplot(Ozone ~ Wind | Month, data = airquality, panel = function(x, y, ...){
panel.xyplot(x, y, ...)
panel.lmline(x, y, col = 2)
})
print(p)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
?panel.abline()
library(datasets)
data(airquality)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library(lattice)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library(ggplot2)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
qplot(Wind, Ozone, data = airquality)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + geom_smooth()
ppoist(3, lambda = 2.5*4)
ppois(3, lambda = 2.5*4)
ppoist(40, 9*5)
ppois(40, 9*5)
library(UsingR)
data(father.son)
x <- father.sonsheight
library(UsingR)
data(father.son)
x <- father.son$sheight
((mean(x) + c(-1, 1) * qnorm(0.975) * sd(x)/sqrt(length(x))))/12
x <- 5
t <- 94.32
poisson.test(x, T = t)
attr(,"conf.level")
x <- 5
t <- 94.32
lambda <- x/t
round(lambda + c(-1, 1) * qnorm(0.975) * sqrt(lambda/t), 3)
x <- 10
t <- 60
lambda <- x/t
round(lambda + c(-1, 1) * qnorm(0.975) * sqrt(lambda/t), 3)
poisson.test(x, T = t)
?poisson.test
poisson.test(10 * 60, 60)
?pnorm
pnorm(93, 100, 10)
qnorm(.95, mean = 100, sd = 10 / sqrt(50))
qnorm(.95, mean = 100, sd = 1)
qnorm(.95, mean = 11000, sd = 1)
.5^5
qnorm(.2, mean = .5, sd = (1/12)
)
round(ppois(20, lambda = 16.5 * 2) * 100, 1)
round(ppois(10, lambda = 5 * 3) * 100, 1)
qnorm(.95, mean = 1100, sd = 10 / sqrt(50))
qnorm(.95, mean = 1100, sd = 75 / sqrt(50))
qnorm(.95, mean = .5, sd = (1/12)/(sqrt(1000)))
qnorm(.95, mean = 11000, sd = (10/sqrt(100)))
qnorm(.95, mean = 1100, sd = 75 / sqrt(50))
qnorm(.95, mean = 1100, sd = 75 / sqrt(100))
choose(5, 4)*.5^4 + choose(5, 5)*.5 ^ 5
choose(5, 4)*.5^5 + choose(5, 5)*.5 ^ 5
?read.csv
data_ <- read.csv(unz(destfile, "stormdata.csv"))
years <- as.Date(data_$BGN_DATE, format = "%m/%d/%Y %H:%M:%S")
years <- as.numeric(format(years, "%Y"))
getwd()
setwd("~/GitHub/Data-Scientist-MOOC/5 - Reproducible Research/Assignment 2")
data_ <- read.csv("./data/stormdata.zip.out", nrows = 10000)
years <- as.Date(data_$BGN_DATE, format = "%m/%d/%Y %H:%M:%S")
years <- as.numeric(format(years, "%Y"))
str(years)
factor(years)
data <- read.csv(unz(destfile, "stormdata.csv"), rows  = 20000:)
data <- read.csv(unz(destfile, "stormdata.csv"), rows  = 20000:30000)
data <- read.csv(unz(destfile, "stormdata.csv"), rows  = 10000)
data <- read.csv(unz(destfile, "stormdata.csv"), nrows  = 20000:)
data <- read.csv(unz(destfile, "stormdata.csv"), nrows  = 20000:30000)
destfile <- "./data/stormdata.zip"
data <- read.csv(unz(destfile, "stormdata.csv"), nrows  = 20000:30000)
data <- read.csv("./data/stormdata.zip.out", nrows = 20000:30000)
data
head(data)
data <- read.csv("./data/stormdata.zip.out", nrows = 10000)
data$EVTYPE<-toupper(data$EVTYPE)
data$EVTYPE<-gsub(" ","/", data$EVTYPE , fixed=TRUE)
data$EVTYPE<-gsub("//","/", data$EVTYPE , fixed=TRUE)
data$EVTYPE<-gsub(",","/", data$EVTYPE , fixed=TRUE)
data$EVTYPE<-gsub("-","/", data$EVTYPE , fixed=TRUE)
injuries<-aggregate(data[, "INJURIES"], by = list(data$EVTYPE), FUN = "sum",na.rm=TRUE)
colnames(injuries)<-c("EVTYPE", "NUMBER")
injuries<-head(arrange(injuries, injuries[, 2], decreasing = T), n=15)
fatalities<-aggregate(data[, "FATALITIES"], by = list(data$EVTYPE), FUN = "sum",na.rm=TRUE)
colnames(fatalities)<-c("EVTYPE", "NUMBER")
fatalities<-head(arrange(fatalities, fatalities[, 2], decreasing = T), n=15)
library(ggplot2)
library(plyr)
require(gridExtra)
library(sqldf)
data$EVTYPE<-toupper(data$EVTYPE)
data$EVTYPE<-gsub(" ","/", data$EVTYPE , fixed=TRUE)
data$EVTYPE<-gsub("//","/", data$EVTYPE , fixed=TRUE)
data$EVTYPE<-gsub(",","/", data$EVTYPE , fixed=TRUE)
data$EVTYPE<-gsub("-","/", data$EVTYPE , fixed=TRUE)
injuries<-aggregate(data[, "INJURIES"], by = list(data$EVTYPE), FUN = "sum",na.rm=TRUE)
colnames(injuries)<-c("EVTYPE", "NUMBER")
injuries<-head(arrange(injuries, injuries[, 2], decreasing = T), n=15)
fatalities<-aggregate(data[, "FATALITIES"], by = list(data$EVTYPE), FUN = "sum",na.rm=TRUE)
colnames(fatalities)<-c("EVTYPE", "NUMBER")
fatalities<-head(arrange(fatalities, fatalities[, 2], decreasing = T), n=15)
injuries
fatalities
injuriesPlot <- qplot(EVTYPE, data = injuries, weight = NUMBER, geom = "histogram", binwidth = 1) +
scale_y_continuous("Number of Injuries") +
theme(axis.text.x = element_text(angle = 45,
hjust = 1)) + xlab("Severe weather type") +
ggtitle("Total injuries by severe weather event in the U.S. 1990 - 2011")
fatalitiesPlot <- qplot(EVTYPE, data = fatalities, weight = NUMBER, geom = "histogram", binwidth = 1) +
scale_y_continuous("Number of Fatalities") +
theme(axis.text.x = element_text(angle = 45,
hjust = 1)) + xlab("Severe weather type") +
ggtitle("Total fatalities by severe weather event in the U.S. 1990 - 2011")
injuriesPlot
barchart(injuries)
barplot(injuries)
qplot(injuries)
qplot(injuries)
data_ <- read.csv("./data/stormdata.zip.out", nrows = 10000)
# assign variables to the relevant columns
events <- data_$EVTYPE
fatalities <- data_$FATALITIES
injuries <- data_$INJURIES
# convert date into years
years <- as.Date(data_$BGN_DATE, format = "%m/%d/%Y %H:%M:%S")
years <- as.numeric(format(years, "%Y"))
# factor variable to distinguish events
events_factors <- factor(events)
DF <- data.frame(events, fatalities, injuries)
total_fatalities <- tapply(fatalities, events_factors, FUN = sum)
total_injuries <- tapply(injuries, events_factors, FUN = sum)
DF2 <- data.frame(total_fatalities, total_injuries)
DF2 <- data.frame(t(DF2))
DF
DF2
injuries1
data$EVTYPE<-toupper(data$EVTYPE)
data$EVTYPE<-gsub(" ","/", data$EVTYPE , fixed=TRUE)
data$EVTYPE<-gsub("//","/", data$EVTYPE , fixed=TRUE)
data$EVTYPE<-gsub(",","/", data$EVTYPE , fixed=TRUE)
data$EVTYPE<-gsub("-","/", data$EVTYPE , fixed=TRUE)
injuries1<-aggregate(data[, "INJURIES"], by = list(data$EVTYPE), FUN = "sum",na.rm=TRUE)
colnames(injuries1)<-c("EVTYPE", "NUMBER")
injuries1<-head(arrange(injuries1, injuries1[, 2], decreasing = T), n=15)
fatalities1<-aggregate(data[, "FATALITIES"], by = list(data$EVTYPE), FUN = "sum",na.rm=TRUE)
colnames(fatalities1)<-c("EVTYPE", "NUMBER")
fatalities1<-head(arrange(fatalities1, fatalities1[, 2], decreasing = T), n=15)
injuries1
injuries
injuries1
total_fatalities
injuriesPlot <- qplot(EVTYPE, data = injuries, weight = NUMBER, geom = "histogram", binwidth = 1) +
scale_y_continuous("Number of Injuries") +
theme(axis.text.x = element_text(angle = 45,
hjust = 1)) + xlab("Severe weather type") +
ggtitle("Total injuries by severe weather event in the U.S. 1990 - 2011")
class(injuries1)
class(total_injuries)
class(total_injuries$HAIL)
class(total_injuries[$HAIL]0])
class(total_injuries[]0])
class(total_injuries[0])
injuries1
class(injuries1)
class(injuries1[0])
DF2
DF2 <- data.frame(total_fatalities, total_injuries)
DF2
injuries1
class(injuries10)
class(injuries1)
name(injuries1)
names(injuries1)
total_injuries
events_factors
a <- data.frame(events_factors)
a
?gl
getwd()
list.files()
setwd("~/GitHub/Data-Scientist-MOOC/5 - Reproducible Research/Assignment 1")
list.files()
if (!file.exists("data")) {dir.create("data")}
# file URL and destination file
fileUrl <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2Factivity.zip"
destfile <- "./data/activity.zip"
# download the file and note the time
download.file(fileUrl, destfile = destfile)
dateDownloaded <- date()
options(rpubs.upload.method = "internal")
baseline <- c(140, 138, 150, 148, 135)
week2 <- c(132, 135, 151, 146, 130)
results <- data.frame(baseline, week2)
results
?t.test
t.test(x = results$baseline, y = results$week2, alternative = "two.sided")
t.test(x = results$baseline, y = results$week2, alternative = "two.sided", paired = TRUE)
mn + c(1, -1) * qt(1 - (a/2) * (s/sqrt(n)))
n <- 9
mn <- 1100
s <- 30
a <- .05
mn + c(1, -1) * qt(1 - (a/2) * (s/sqrt(n)))
mn + c(1, -1) * qt(1 - (a/2, n-1) * (s/sqrt(n)))
mn + c(1, -1) * qt(1 - (a/2), n-1) * (s/sqrt(n)))
mn + c(1, -1) * qt(1 - (a/2), n-1) * (s/sqrt(n))
1 - (a/2)
n = 9
x_bar = 1100
sdev = 30
a = 0.05
round(x_bar + c(-1,1)*qt(1 - (a/2), n-1) * sdev/sqrt(n))
n <- 9
mn <- 1100
s <- 30
a <- 0.05
mn + c(1, -1) * qt(1 - (a/2), n-1) * (s/sqrt(n))
mn + c(1, -1) * qt(1 - (a/2), n-1) * s/sqrt(n)
n <- 9
mn <- 1100
s <- 30
a <- 0.05
mn + c(1, -1) * qt(1 - (a/2), n-1) * s/sqrt(n)
round(x_bar + c(-1,1)*qt(1 - (a/2), n-1) * sdev/sqrt(n))
n = 9
x_bar = 1100
sdev = 30
a = 0.05
round(x_bar + c(-1,1)*qt(1 - (a/2), n-1) * sdev/sqrt(n))
mn + c(-1, 1) * qt(1 - (a/2), n-1) * sdev/sqrt(n)
n <- 9
mn <- 1100
s <- 30
a <- 0.05
mn + c(-1, 1) * qt(1 - (a/2), n-1) * s/sqrt(n)
n <- 9
mn <- 1100
s <- 30
a <- 0.05
mn + c(1, -1) * qt(1 - (a/2), n-1) * s/sqrt(n)
binom.test(51,235,(1/6),alternative="greater"
)
?binom.test
binom.tset(c(3, 1), p=0.5)
binom.test(c(3, 1), p=0.5)
binom.test(c(3, 1), p = 0.5, alternative = "greater")
1/100
10/1787
ppois(n-1, 1, lower.tail = FALSE)
ppois(n-1, 1, lower.tail = FALSE)
n <- 100
ppois(n-1, 1, lower.tail = FALSE)
ppois(n-1, 100, lower.tail = FALSE)
p2 <- (10/1787) * 100
p2
?ppois
p1 <- 1/100
p2 <- (10/1787) * 100
p1
p2
p1 <- 1
p2 <- (10/1787) * 100
p2
ppois(10, p1, lower.tail = FALSE)
s <- sqrt((p1 * (1 - p1)/n)
s <- sqrt((p1 * (1 - p1)/n)
s
s <- sqrt((p1 * (1 - p1)/n)
)
s
s
p1
p1 <- 1/100
p2 <- (10/1787) * 100
n <- 100
s <- sqrt((p1 * (1 - p1)/n))
s
ppois(p2, 1, lower.tail = FALSE)
p2
ppois(p2-1, 1, lower.tail = FALSE)
ppois( 1, p2-1, lower.tail = FALSE)
p
ppois(1, p2-1, lower.tail = FALSE)
ppois(p2-1, 1, lower.tail = FALSE)
ppois(p2-1, 1, lower.tail = TRUE)
ppois(p2-1, 1, lower.tail = FALSE)
ppois(p2, 1, lower.tail = FALSE)
R
ppois(p2, 1, lower.tail = TRUE)
p2
ppois(p2-1, 1, lower.tail = TRUE)
ppois(p2-1, 1, lower.tail = FALSE)
ppois(p2, 1, lower.tail = TRUE)
s <- sqrt((p1 * (1 - p1)/n))
test_z = (p1 - p2) / s
ppois(test_z, lower.tail = TRUE)
pnorm(test_z, lower.tail = TRUE)
p1 <- 1
p2 <- 10/1787
n <- 100
#s <- sqrt((p1 * (1 - p1)/n))
#ppois(p2, 1, lower.tail = TRUE)
# When the population size is much larger (at least 10 times larger) than the sample size, the standard deviation can be approximated by:
# ﾏパ = sqrt[ P * ( 1 - P ) / n ]
s <- sqrt((p1 * (1 - p1)/n))
test_z = (p1 - p2) / s
pnorm(test_z, lower.tail = TRUE)
pnorm(test_z, lower.tail = FALSE)
p1 <- 1/100
p2 <- 10/1787
n <- 100
#s <- sqrt((p1 * (1 - p1)/n))
#ppois(p2, 1, lower.tail = TRUE)
# When the population size is much larger (at least 10 times larger) than the sample size, the standard deviation can be approximated by:
# ﾏパ = sqrt[ P * ( 1 - P ) / n ]
s <- sqrt((p1 * (1 - p1)/n))
test_z = (p1 - p2) / s
pnorm(test_z, lower.tail = FALSE)
?pnorm
p1
p2
# get probabilites per day
p1 <- 1/100
p2 <- 10/1787
n <- 100
#s <- sqrt((p1 * (1 - p1)/n))
#ppois(p2, 1, lower.tail = TRUE)
# When the population size is much larger (at least 10 times larger) than the sample size, the standard deviation can be approximated by:
# ﾏパ = sqrt[ P * ( 1 - P ) / n ]
s <- sqrt((p1 * (1 - p1)/n))
# get the releveant quantile(lower) expressed in standard deviations
test_z = (p1 - p2) / s
pnorm(test_z, lower.tail = FALSE)
p = 1/100
p_ = 10/1787
n=1787
serror = sqrt(p*(1-p)/n)
test_z = (p-p_)/serror
pnorm(test_z, lower.tail=FALSE)
p
p1
p_
p2
s
p1 <- 1/100
p2 <- 10/1787
n <- 1787
#s <- sqrt((p1 * (1 - p1)/n))
#ppois(p2, 1, lower.tail = TRUE)
# When the population size is much larger (at least 10 times larger) than the sample size, the standard deviation can be approximated by:
# ﾏパ = sqrt[ P * ( 1 - P ) / n ]
s <- sqrt((p1 * (1 - p1)/n))
# get the releveant quantile(lower) expressed in standard deviations
test_z = (p1 - p2) / s
pnorm(test_z, lower.tail = FALSE)
n <- 18
n_treated <- 9; n_placebo <- 9
mn_treated <- -3; mn_placebo <- 1
s_treated <- 1.5; s_placebo <- 1.8
n <- 18
mn_treated <- -3; mn_placebo <- 1
s_treated <- 1.5; s_placebo <- 1.8
n_x <- 9; n_y <- 9
# calculate the pooled variance
sp <- sqrt(((n_treated-1) * s_treated^2 + (n_y-1) * s_placebo^2) / (n_x + n_y - 2))
# calculate the confidence interval interval
(mn_treated - mn_placebo) + c(-1, 1) * qt(0.95, df) * sp * sqrt(1/n_x + 1/n_y)
n <- 18
n_treated <- 9; n_placebo <- 9
mn_treated <- -3; mn_placebo <- 1
s_treated <- 1.5; s_placebo <- 1.8
n <- 18
mn_treated <- -3; mn_placebo <- 1
s_treated <- 1.5; s_placebo <- 1.8
n_x <- 9; n_y <- 9
# calculate the pooled variance
sp <- sqrt(((n_treated-1) * s_treated^2 + (n_y-1) * s_placebo^2) / (n_x + n_y - 2))
# calculate the confidence interval interval
(mn_treated - mn_placebo) + c(-1, 1) * qt(0.95, n-2) * sp * sqrt(1/n_x + 1/n_y)
?power.t.test
power.t.test(n,. delta = mn, sd = s, sig.level = 0.05)
power.t.test(n, delta = mn, sd = s, sig.level = 0.05)
power.t.test(n = 100, delta = .01, sd = .04, sig.level = 0.05, type = "one.sample", alt = "one.sided")
power.t.test(delta = .01, sd = .04, type = "one.sample", alternative = "one.sided")
power.t.test(delta = .01, sd = .04, power = .9, type = "one.sample", alternative = "one.sided")
n <- 288
n_treated <- 44; n_placebo <- 42.04
mn_treated <- 42.04; mn_placebo <- 42.04
s_treated <- 288; s_placebo <- 288
# calculate the pooled variance
sp <- sqrt(((n_treated-1) * s_treated^2 + (n_y-1) * s_placebo^2) / (n_x + n_y - 2))
sp
(mn_treated - mn_placebo) + c(-1, 1) * qt(0.95, n-2) * sp * sqrt(1/n_x + 1/n_y)
n <- 288
n_treated <- 44; n_placebo <- 42.04
mn_treated <- 12; n_placebo <- 12
s_treated <- 288; s_placebo <- 288
# calculate the pooled variance
sp <- sqrt(((n_treated-1) * s_treated^2 + (n_y-1) * s_placebo^2) / (n_x + n_y - 2))
# calculate the confidence interval interval
(mn_treated - mn_placebo) + c(-1, 1) * qt(0.95, n-2) * sp * sqrt(1/n_x + 1/n_y)
n <- 288
n_treated <- 288; n_placebo <- 288
mn_treated <- 44; n_placebo <- 42.04
s_treated <- 12; s_placebo <- 12
# calculate the pooled variance
sp <- 12
# calculate the confidence interval interval
(mn_treated - mn_placebo) + c(-1, 1) * qt(0.95, n*2-2) * sp * sqrt(1/n_treated + 1/n_placebo)
(mn_treated - mn_placebo) + c(-1, 1) * sp * sqrt(1/n_treated + 1/n_placebo)
std_error <- sp * sqrt(1/n_treated + 1/n_placebo)
std_error
z <- (mn_treated-mn_placebo)/std_error
z
p.v = 2 * pnorm(-abs(z.11))
p.v = 2 * pnorm(-abs(z))
2 * pnorm(-abs(z))
mean.1 = 44
mean.2 = 42.04
sds = 12
n = 288
st.error = sds*sqrt(1/n + 1/n)
z.11 = (mean.1 - mean.2)/st.error
z.11
st.error
st.error = sds*sqrt(1/n + 1/n)
st.error
s
sds
s <- 12
n <- 288
n_treated <- 288; n_placebo <- 288
mn_treated <- 44; mn_placebo <- 42.04
s <- 12
std_error <- s * sqrt(1/n_treated + 1/n_placebo)
# get the z value
z <- (mn_treated-mn_placebo)/std_error
# two sided
2 * pnorm(-abs(z))
.05/10
mean.diff = -3-1
df = (9 + 9 - 2)
m_tr = -3
m_pb = 1
s_tr = 1.5
s_pb = 1.8
pooled.var = (s_tr^2 * 9 + s_pb^2 * 9)/df
se.diff = sqrt(pooled.var/9 + pooled.var/9)
t.obt = mean.diff / se.diff
t.obt
pooled.var
n <- 18
mn_treated <- -3; mn_placebo <- 1
s_treated <- 1.5; s_placebo <- 1.8
n_x <- 9; n_y <- 9
# calculate the pooled variance
sp <- sqrt(((n_treated-1) * s_treated^2 + (n_y-1) * s_placebo^2) / (n_x + n_y - 2))
sp
sp <- sqrt(((n_x-1) * s_treated^2 + (n_y-1) * s_placebo^2) / (n_x + n_y - 2))
sp
pooled.var
sp <- sqrt((n_x * s_treated^2 + n_y * s_placebo^2) / (n_x + n_y - 2))
sp
pooled.var
mean.diff = -3-1
df = (9 + 9 - 2)
m_tr = -3
m_pb = 1
s_tr = 1.5
s_pb = 1.8
pooled.var = (s_tr^2 * 9 + s_pb^2 * 9)/df
pooled.var
sp <- sqrt((n_x * s_treated^2 + n_y * s_placebo^2) / (n)
)
sp
sp <- sqrt(((n_x * s_treated^2) + (n_y * s_placebo^2)) / (n_x + n_y - 2))
s
se.diff
rexp(40, .2)
hist(rexp(40, .2))
hist(rexp(40, .2))
hist(rexp(40, .2))
hist(rexp(40, .2))
hist(rexp(40, .2))
hist(rexp(40, .2))
hist(rexp(40, .2))
rexp(40, .2)
rexp(40, .2)
rexp(40, .2)
hist(rexp(40, .2))
hist(rexp(40, .2))
rexp(40, .2)
